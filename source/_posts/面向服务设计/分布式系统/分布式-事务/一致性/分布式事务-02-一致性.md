---
title: 一致性-02-分布式事务
date: 2021-05-11 12:55:26
tags:
---

## 分布式事务--数据一致性引擎概览

### 应用场景

一般，广告检索系统都承载着公司很大比重的营收占比。

计费系统是广告系统的偏底层一环，承担着反作弊、计算费用、优惠扣减、费用实际扣除等职责。整个扣费流程涉及到了计费单、营销系统、支付账务系统、预算系统等的上下游数据一致性问题。

并且，由于存在CPT、CPA、CPC等不同类型的计费方式，而广告点击有流量不可回溯等特点（普通支付场景可以让用户重试），计费的数据一致性引擎的合理设计就变得尤为重要了。

### 一致性保障方案选择

支付业务一般的可以分为两种

- 一种是有支付牌照的公司，直接和账户和银行打交道
  - 一般需要非常强硬的保障手段来实现分布式下数据的强一致性。比如TCC的类二阶段提交方式
- 另一种是调用第三方支付服务，实现支付业务。
  - 相对来说，一致性要求不是非常苛刻，有不少的解决方案可供选择，比如本地消息表、事务型消息等等

当前项目的场景显然属于第二种。那么，应该怎么合理选择实现方式呢：

#### 事务型消息

优点：实现方案轻量，改造成本小，适合为对实时性不是特别高的场景。

缺点：就是每个系统只能负责自己这一块，流程变得冗长，不利于问题排查。业务耦合程度可能要高一些。

#### TCC模式

系统实现真的是非常的重。

- 需要流程中的所有系统，按照既定的规范来实现一套包含了try/commit/cancel三个处理逻辑的调用模板。 
- 需要流程中的所有系统，按照既定的规范来创建主事务表和分支事务表，来记录事务状态和调用参数及路由。
-  需要参与者创建事务幂等表，实现拒绝空回滚或拒绝后到达的资源扣减等的防悬挂逻辑。

光是让各系统配合实现几个接口，我觉得，如果没有非常大的资金风险压迫，没几个人会配合。

而且，TCC可能更适用于有用户直接参与的资源扣减场景，因为引擎的基本思路是失败时操作回滚，保证上下游一致。

但是，上面也说过了，广告点击流的特点是流量不可回放，用户不可能因为这次计费没成功，就帮我们再点一次。所以，我们的一致性引擎的恢复逻辑，不仅要支持回滚，还要支持重试。不可漏掉每一次点击计费。

#### saga模式

最终，我们参考saga模式，选择的是类saga的状态机引擎的补偿模式。

这种方式的优点是，对老系统改造成本友好，即使实现接口也比较方便，通过状态机编排执行节点链，并配置重试回滚方式、实时异步策略。

事务信息存储方式相对灵活，主要看自己公司的各种存储的可靠性和一致性的承诺。

### 数据一致性引擎: saga模式

#### 引擎架构图

![Image](https://mmbiz.qpic.cn/mmbiz_png/xE6oscyT531rYZT3GBGOAHYiaBqrVEmcZHSCLhUsnUzqJjRWp0V1Rep93Bpjicqs1bbp5U4KEx1LWibdnYicCBL2bQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 结构组成

- *状态机* 实现节点执行顺序编排及其他执行特性
- *节点* 业务需要实现的逻辑节点，比如计费的cpc扣费逻辑，需要有前置check、price调价、coupon优惠券、pmc扣费等执行节点
- *补偿逻辑* 属于节点的一部分实现，每个执行节点需要实现当前节点的补偿逻辑，以供执行异常时进行恢复操作
- *钩子函数* 在引擎执行前和执行后，允许业务系统执行自有的特殊操作
- *定时任务* 异常数据恢复的触发入口

#### 其他特性

- *补偿方式* 可配置，有重试/回滚 两种补偿方式可选；重试补偿时，执行顺便和正常顺序一致，回滚补偿时，从最后一个执行节点往前回滚
- *补偿触发时效* 可配置，有实时/异步延时 两种触发策略可选，如果有资源悬挂的风险，建议选异步延时触发
- *重试次数及时间衰减* 可配置，按业务实际情况定制衰减序列

#### 状态机配置实例

```
{
  "name": "xxxx_xxxx_xxxx",
  "comment": "cpc计费状态机",
  "firstNodeName": "check",
  "nodes": {
    "check": {
      "nextNodeName": "land",
      "preNodeName": "",
      "skipRecover": true
    },
    "land": {
      "nextNodeName": "antiFraud",
      "preNodeName": "check",
      "skipRecover": false
    },
    "antiFraud": {
      "nextNodeName": "realPrice",
      "preNodeName": "land",
      "skipRecover": false
    },"...":{"..."}
  },
  #重试次数
  "retryCount": "4", 
  #重试时间衰减
  "timeDecaySeries": ["1","3","5","10"], 
  #补偿策略，重试/回滚
  "recoverType": "Retry",
  #触发时效，实时触发/异步触发
  "compensateTimeliness": "ASYNC"
}
```

#### 引擎初始化

```
DTConfig.builder()
    .setAppName("billing")//配置appName
    .setLogStoreStrategy(StoreStrategyEnum.DEFAULT_STORE)//存储策略
    .setRedisConfig(redisConfigPath) //设置redis配置
    .setDBTableConfig(mysqlConfigPath) //mysql配置
    .setZKConfig(configPath) // wConfig 配置 ，切流灰度使用
    .setStateMachinePath(stateMachinePath)//状态机配置项地址
    .setNegligibleErrorCode(BillingDTConstants.serious_error_code_str) //当前系统关键异常code集合（不可忽略的致命异常，供恢复逻辑使用）
    .build();
```

#### 引擎调用

```
//本次调用所使用的状态机名称
String stateMachineName="ecpm_state_machine"; //当前请求使用到的状态机名称（和状态机配置中的name一致）
//获取引擎实例
DTBizEngine dtBizEngine=new SagaDTBizEngine();
//组装入参执行调用
DTResponse response=  dtBizEngine.start(new DTEngineRequest(bizType,bizId,stateMachineName,originContext));
//打印结果
System.out.println(response.getData());
```

#### 异步化（参考dubbo的异步化实现的）

主线程

```
try {
   //创建 DTFurure ,传入 (DTEngineRequest request , int timeout)
   DTFuture mFuture=new DTFuture(request, 1000);
   //将该future传递下去，也可以用其他方式传递，这里直接放到了request扩展字段做示例
   request.getExtendField().put("MY_KEY",mFuture);
   //异步线程调用 
   EcpmEventBus.getInstance().post(new EcpmBillingEvent(request));
   //有限时间超时等待，get到的结果是业务完成时设置进来的对象，业务系统可以按自己的场景转换
   Object future= mFuture.get(1000); //单位是毫秒
   //do something

  } catch (Exception e) {
 }
```

执行线程

```
//do something ...

DTFurure futrue=(DTFurure)request.getExtendField().get("MY_KEY");

DTFuture.received(futrue.getId(),response);
```





## 分布式事务2-- 数据一致性引擎原理

> 分布式事务解决什么问题
>
> - *准备调用下游扣费，或刚调起下游扣费接口，服务宕机了，怎么办？*
> - *调用下游超时，不知道下游是否执行怎么办？*
> - *调用下游时发生网路堵塞，回滚先到扣费操作后到被悬挂怎么办？*
> - *整个事务需要同时满足重试和回滚操作怎么办？*
> - *因为支付系统大面积重试时，优惠券节点也要重试么？*
> - *重试失败怎么办？重试间隔怎么设置？*

下面就带着这些待解决的场景问题，看看 DT 引擎是个什么东西

### DT 引擎是个什么东西

![Image](https://mmbiz.qpic.cn/mmbiz_png/xE6oscyT532jLJNoZH2DKo0XkmGoibsPVkfHP9DkJ8CSICmttBZeQDwYTMnlwH9HACOiaQcvdEeo9hqsBjxn7LYQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)从上图可以看到，DT 的核心组成包括三大部分：

- *事务协调器*：负责节点编排、结果判断、分支路由等主要功能。
- *业务执行及补偿节点* ：负责调用业务系统实现的多个执行节点。
- *异步补偿触发*：负责在执行异常时，异步调起恢复任务并触发执行。

**「总结下，DT 是个以状态机为基础的，补偿式的分布式长事务一致性保障引擎。」**

下面将详述每个模块的实现方案和细节。

### DT 引擎原理介绍

**「理论基础」**：是从Hector&Kenneth在1987年发表的《Sagas》论文中演化而来：

![Image](https://mmbiz.qpic.cn/mmbiz_png/xE6oscyT532jLJNoZH2DKo0XkmGoibsPV6iafWicVp2q6BkiakhygY9bm6pz9ez7W4ooSehcXORuPehagNfwg3NiaMg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图中绿色的部分是正向执行逻辑，发起方逐个调用，参与者不分阶段，直接执行并提交本地事务.

当链路中某个参与者执行逻辑发生异常时，则依据实际配置，执行补偿--回滚或重试。

*适用场景*：

-  业务流程长、业务流程多
-  业务场景除了回滚还有重试等场景。
-  参与者没法保证提供 TCC 接口。

优势：

-  一阶段提交本地事务，无锁，高性能、事件驱动架构；
- 参与者可异步执行，高吞吐；补偿服务易于实现。

缺点：

- 不保证隔离性

### 模块设计详解

相比Seate里的saga， 原理都是一样的，但是内部实现很多实现方案进行了精炼和一些专属定制化的开发。

比如，saga 中的状态机定义内容非常庞大，几乎所有的内容都出现在了配置文件中，而 DT 精简到了只剩下节点编排，且顺序固定，不支持节点间路由跳转（因为感觉也没必要~）。

诸如此类的定制等等~

其目的，不是为了重复造轮子，是为了有一致性诉求，但是不想对接庞大的解决方案的同学们，提供一种轻量级的处理方案。

#### 事务协调器

协调器的主要职责，是执行节点的流程编排、事务的开启、节点状态的维护和上报、全局状态的维护和更新、全局事务完结后的后续处理等。![Image](https://mmbiz.qpic.cn/mmbiz_png/xE6oscyT532jLJNoZH2DKo0XkmGoibsPVuhotJZBDuYibcmOwGXNR2H9pHROkpBTjduuKHjicJAVmr0xj8iaSzTq8Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)整个事务协调器类图如图所示：

1. `DTBizEngine`接口定义了引擎的执行入口，具体实现策略都继承自它。
2. `SagaDTBizEngine` 是saga模式的具体实现类。
3. 通过`DTStart` 注解实现启动拦截器，执行事务启动初始化操作。
4. 通过`DTAction` 注解实现业务节点拦截器，执行数据上报和状态维护。
5. 引擎通过`config`类拿到业务配置的`DTactionService`实例执行链，执行 `action`方法以触发业务逻辑。
6. `TriggerManager`负责调取*框架定义+业务自定义*的**「钩子函数」**，负责处理各个不同的执行阶段的特殊处理。
7. 整个业务流程，均由事务协调器协调处理。业务系统只需要实现每个节点的 `DTactionService.action` 接口和 `compensate` 接口

**「为了达到进度协调且保证各节点之间的数据一致性，有一些核心的问题需要解决。下面我们详细说明」**

#### 状态机的设计和维护

状态机的配置决定了事务的节点编排和执行流程。既要决定正常的业务执行流程，还要考虑不同场景下的可配置策略。

##### 重试和回滚

回滚，需要从最后一个节点往前回滚。而重试，则需要从前往后执行，因此，状态机节点需要和二叉树一样，将pre 和next节点维护起来。

目前这种方式，是一种极简方式，适用于业务流程比较固定的场景。如果有节点路由的诉求，那另当别论了。

##### 异常捕获

业务执行过程中可能会遇到不同类别的异常。

有些异常是可以忽略的，比如某作弊流量查某个关键配置时未查到，可以直接过滤，不进行后续流程。而个别的严重异常是我们不希望忽略的，比如调支付系统失败，超时等等。

而有些节点，包含了上述两种异常，而有些节点，所有异常均不能忽略。

所以，我们在捕获异常方面会支持两种配置方式：
**「整个节点异常不可忽略」**
**「不可忽略的异常码列表」**

如果当前节点配置了所有异常不可忽略，会直接进入补偿流程。如果没有配置该参数，则会在不可忽略的异常码列表中查询匹配。

##### 重试时间衰减

为了防止下游系统异常恢复不及时和异常请求因特殊情况被防止无限期补偿等场景，我们做了重试时间衰减策略。该时间衰减序列被维护在状态机配置中，比如
**「1,3,5,10」**
则，框架在捞取异常数据进行处理时，会计算上次补偿的时间是否满足该时间序列，再进行执行。

#### 主事务和分支事务

*我们需要依赖主事务串联整个流程，依赖分支事务在执行异常时感知各参与者的执行结果。*

一般在TCC模式下，绝大部分情况都以*本地数据库事务*为依托，会把主事务的创建、参与者的调用包在本地事务内部，这样，使用同一个数据库创建主事务和分支事务表，天然保证和本地业务数据的一致性。这样数据的压力也会有所增加，基本都是在分库分表之后，把压力均摊到分库上完成性能要求。

但是，还有一些情况另外，比如我们目前的业务，为了提高性能，没有启动本地事务，相当于是在裸跑。

那么，一个关键的问题就是数据存储的稳定性和流程阻断方案的完善。

*一是*需要一个高性能的存储来满足数据的强一致性要求，可以允许存储操作失败，但是决不允许接口返回成功，实际上数据丢失的情况发生。
*二是*一个完善的流程阻断方案：我们的存储操作一般分为前置操作和后置操作，如主事务插入和分支事务插入都是前置操作，而分支事务状态更新则是后置操作。在前置操作时失败，则流程阻断，返回失败，让调用方重试或框架补偿。

*最终希望起到的作用是*：
(1)只要存储中没有，那就是肯定没执行；
(2)而如果在存储中查到了记录，框架会认为，曾经有可能执行过，还需要看对应的状态执行对应的补偿。

#### 流程串联

框架需要确定后置处理器和钩子函数的注册时机和方式，需要把主事务的开启，执行节点状态的更新，全部执行完成后的处理逻辑编织在一起，等等。

*具体方法*：使用拦截器的方式，在事务开启前后、节点执行前后，进行事务信息维护和更新，保证流程和数据相互匹配

#### 服务匹配和调起

执行到每个节点，都需要获取参与者的对应服务实例。这个地方之前还会面试问过，问我异常恢复的时候怎么做到通过分支事务表里记录的字符串，调起对方的rpc服务。

这块的实现其实也有很多种，之前工作中用到的tcc模式的dtx引擎，是依托spring框架，使用XMap技术将配置在xml中的对应服务解析成对应的 Javabean,并匹配本地注册中心的服务端信息，调起对应服务。

DT中，我们用了一种比较简单的方法，那就是`「ServiceLoader」`，非常有用的一个获取同一接口下所有实现类服务的方法。

只需三步:

- 创建接口。
  `com.cjh.test.Hello`
- 创建实现类。
  `com.cjh.test.AHelloImpl` 
  `com.cjh.test.BHelloImpl`
- 指定位置创建接口文件. 在
  `resource/META-INF/service`
  文件夹下，创建名为
  **「com.cjh.test.Hello」** 
  的文件，将 
  `com.cjh.test.AHelloImpl`
  `com.cjh.test.BHelloImpl`
  这两行文本填入

ok 完事~ 所以只要框架指定一个包含了 action 和 compesate 的接口，而业务系统的各个节点都实现了该接口，我们就可以方便的调起这些服务~

```
//示例代码
ServiceLoader<AAA> serviceLoader=ServiceLoader.load(AAA.class);

for (AAA load : serviceLoader) {
  System.out.println(load);
}

LoadInterface loadInterface= EnhancedServiceLoader.load(LoadInterface.class,"BLoad");
loadInterface.execute();

Method method = loadInterface.getClass().getMethod("execute");
method.invoke(loadInterface);

EnhancedServiceLoader.load(LoadInterface.class,"ALoad").execute();
```

#### 钩子函数

框架支持业务系统在流程执行开始前、完成后、成功后、异常后执行对应的自定义处理，以满足业务系统的特殊需求。

#### 异步补偿

采用分布式调用方法，定时触发未处理数据的捞取操作，并用数据总线的方式，让系统快速执行补偿。为了防止某条数据被多台机器同时捞取，会加分布式锁进行拒绝拦截。

### 结束语

那么，DT是如何解决开篇提到的那些问题的呢：

1. 在调用扣费服务时发生本服务宕机，说明主事务一定是插入成功的，异步补偿会捞取该主事务记录，并捞取对应的分支事务记录，执行异步补偿。
2. 调用下游超时，说明分支事务已经插入成功，我们更新分支事务为状态未知，等待补偿。
3. 用异步补偿的方式，处理一分钟之前的未完成数据，尽可能避免网络阻塞带来的影响*拒绝空回滚，扣费请求后置的幂等处理，需要下游保障*
4. 支付系统大面积超时，我们会根据分支事务记录来判断其他节点是否已经执行成功，如果执行成功，则跳过重试操作，以避免不必要的系统调用，防止因为冗余的重试调用触发某一系统瓶颈导致全链路崩溃。
5. 时间衰减等  略

















## 高并发消息队列补充篇：在所依赖存储不授信的场景下实现柔性事务降级



### 基础服务支持不到位的坑

#### 项目背景和整理设计思路

项目背景其实还是我们的数据一致性保证长事务引擎。

整体架构如下：![Image](https://mmbiz.qpic.cn/mmbiz_png/xE6oscyT530yxTpTWvojyJtiaOx7PibGLmKicicpErWQMicaMx4Qia15njNTb2icCwTibIskpo1zNMfFxLVjJqGDn2GbyA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 通过状态机来组织和支持多种不同的业务流
- 通过将外部服务节点化来抽象和规范化参与者的服务
- 通过节点的异常捕获来感知参与方的执行结果
- 通过实时或异步的恢复机制，实现柔性事务·

#### 不可缺少的强依赖--存储

想要业务请求保证最终一致，不可能是没有存储参与的一锤子买卖，因为还要考虑本身服务器的抖动，业务上的异步要求等等。所以，存储是一个不可缺少的依赖，如下图所示：![Image](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)存储服务作用在引擎的整个生命周期：

- 在请求进入初期，进行上下文落地(因为广告流量只有一次操作，不像普通支付可以允许用户重试，广告场景下，用户的多次操作需要进行分别计费，并且不太适合利用MQ的ack机制进行重试，因为那需要等流程全部执行完，会影响消息消费速率)
- 在节点执行结束，进行节点执行状态落地(这样，在遇到需要补偿的情况，可以避免冗余调用，防止不需要重试的系统被其他抖动的系统冲击)
- 在异步恢复时，获取上下文和节点执行状态集合，以完成事务的最终一致性处理。

#### 存储的调研和选择

##### 业界的选择--数据库

对于支付类业务，其实，最好的是用数据库。业务层的订单表相当于业务请求上下文，会将请求的所需信息落地(没有上下文落地其实也没关系，返回用户失败即可)。

节点执行状态数据存在和订单表同库的另一个表中，即可支持一个在一个本地事务内保证分布式事务的最终一致性逻辑。

##### 业务特性决定了数据库不合适

由于种种原因，我们这里不太适合用数据库，一个是广告上下文太大，且绝大多时候没有用，为了少数异常存到订单表的话太浪费；二是目前采用实时库+历史库的方式进行，没有分库，如果增加了中间状态表，目前的并发量，对数据库压力会很大，但目前搞分库又不是那么必要。

所以数据库不太适合。

##### 公司自研存储的选择和使用

正好，公司自研了一套基于rocksdb的高性能存储，在读写性能和数据结构方面基本可以代替MySQL和Redis。在公司内部被广泛使用。

两个版本，一个是paxos强一致版本，读写性能稍弱，但保证数据强一致；另一个是普通版本，读写性能更高，但不保证强一致，即有可能主从切换会丢数据。

对于带金融属性的业务来说，在理论上的读写性能满足业务要求的情况下，当然是首选强一致的版本了。特别是业务上下文，丢失的结果就是该请求的整个异常恢复流程无法被正常唤起。

然而，理想照进现实，由于该版本之前应对的业务场景较为简单，并发也没有我们这么大，一些底层调优不到位导致服务抖动频繁。

如果是在大厂，就像之前用OB，只要OB有承若数据不丢，那基本不用考虑丢失的问题。如果丢了，我想可能大概率就会把锅抛给存储团队，限时优化之类。

但，我们小厂可都是*相亲相爱的一家人*，怎么能干这种事。所以选了另一个版本，使用更广泛，更成熟的非强一致版本。而数据丢失的问题由业务自己来想办法。

### 消息队列的介入

#### 非强一致存储为啥会丢数据

![Image](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)如上图所示，该存储架构采用的是主从模式，数据由主写入，同步到从，当主异常时，进行主从切换，恢复服务。

但是，由于不是强一致协议，写主成功即为成功，当主宕机时，虽然主从切换很快，10秒完成，但还没有来得及同步到从的那部分数据，就会因为因为主从切换而丢失。

怎么办？

#### 消息队列登场

为了应对存储不授信的情况，我们引入了消息队列来实现存储的丢失补偿。![Image](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)如上图所示，引入延迟消息进入处理流程。

- 当节点执行发生异常时，发送当前业务上下文到消息队列。如果是正常执行的情况则无需发送。
- 消息的延迟间隔，要大于主从切换的时间，并且需要小于定时任务的触发间隔。比如，主从切换需要10s，那延迟消息的延迟间隔就设置为30s , 接收消息都重新插入上下文到存储。在节点异常一分钟之后，被定时任务捞取，执行处理。

用两个时间差来覆盖掉主从切换带来的数据丢失的影响。

#### 更进一步--存储降级

那么，更极端的情况，如果整个存储服务持续不可用怎么办？

**降级：** 自己的命运要把握在自己手中。目的是保证绝大部分服务正常。![Image](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

- 监控系统。用于收集和汇报操作存储时的异常，并统计错误率和超时率
- 一旦错误率和超时率达到阈值（比如持续30s，所有服务全部超时）执行关联脚本。
- 脚本负责触发配置中心的配置切换，由正常模式切换为柔性模式。
- 柔性模式下，所有涉及存储读写的操作将被忽略，以保障绝大部分请求可以正常执行。
- 遇到执行异常的节点，将上下文发送至消息队列，消费时不再插入存储，而是改为直接消费。

