---
title: 健壮后端服务
date: 2021-05-17 19:37:33
tags:
---

如何避免故障？一句话概括 : 怀疑第三方，防备使用方，做好自己。

## 怀疑第三方

坚持一条信念：“所有第三方服务都不可靠”，不管第三方什么天花乱坠的承诺。

### 接口备份+ 数据备份，制定好业务降级方案

第三方提供了两种方式：1）一种是消息通知服务，只发送变更后的数据；2）一种是 HTTP 服务，需要我们自己主动调用获取数据。我们一开始选择消息同步的方式，因为实时性更高，但是之后就遭遇到消息迟迟发送不过来的问题，而且也没什么异常，等我们发现一天时间已过去，问题已然升级为故障。合理的方式应该两个同步方案都使用，消息方式用于实时更新，HTTP 主动同步方式定时触发（比如1小时）用于兜底，即使消息出了问题，通过主动同步也能保证一小时一更新。

有些时候第三方服务表面看起来正常，但是返回的数据是被污染的。这时需要每隔一段时间，对数据进行备份，方便在数据被污染时做回滚

### 设置超时时间，保障快速失败

某服务调用的一个第三方接口正常响应时间是 50 ms，某天该第三方接口出现问题，大约有 15% 的请求响应时间超过 2s，没过多久服务 load 飙高到 10 以上，响应时间也非常缓慢，即第三方服务将我们服务拖垮了。为什么会被拖垮？没设置超时！我们采用的是同步调用方式，使用了一个线程池，该线程池里最大线程数设置了 50，如果所有线程都在忙，多余的大量请求就堆在队列里中。

正确的做法是和第三方商量确定个较短的超时时间比如 200 ms，这样即使他们服务出现问题也不会对我们服务产生很大影响。

### 慎重选择重试机制

需要结合自己的业务以及异常来仔细斟酌是否使用重试机制。

## 防备使用方

这里又要坚持一条信念：“所有的使用方都不靠谱”，

### 设计一个好的 API（RPC、Restful）避免误用

过去两年间看过不少故障，直接或间接原因来自于糟糕的接口。如果你的接口让很多人误用，那要好好反思自己的接口设计了，接口设计虽然看着简单，但是学问很深，建议大家好好看看 Joshua Bloch 的演讲《How to Design a Good API & Why it Matters（如何设计一个好的 API 及为什么这很重要）》以及《Java API 设计清单》。

下面简单谈谈我的经验：

- 遵循接口最少暴露原则。使用方用多少接口我们就提供多少，接口暴露越多自己维护成本就越高。
- 不要让使用方做接口可以做的事情。如果使用方需要调用我们接口多次才能进行一个完整的操作，那么这个接口设计就可能有问题。比如获取数据的接口，如果仅仅提供 getData(int id) 接口，那么使用方如果要一次性获取 20 个数据，它就需要循环遍历调用我们接口 20 次，不仅使用方性能很差，也无端增加了我们服务的压力，这时提供 getDataList(List idList) 接口显然是必要的。
- 避免长时间执行的接口。还是以获取数据方法为例：getDataList(List idList)。假设一个用户一次传 1w 个 id 进来，我们的服务估计没个几秒出不来结果，而且往往是超时的结果，用户怎么调用结果都是超时异常，那怎么办？限制长度，比如限制长度为 100，即每次最多只能传 100 个 id，这样就能避免长时间执行，如果用户传的 id 列表长度超过100就报异常。
- 参数易用原则。避免参数长度太长，一般超过 3 个后就较难使用，那有人说了我参数就是这么多，那怎么办？写个参数类嘛！此外，避免连续的同类型的参数，不然很容易误用。能用其它类型如 int 等的尽量不要用 String 类型，这也是避免误用的方法。
- 异常。接口应当最真实的反应出执行中的问题，更不能用聪明的代码做某些特别处理。经常看到一些同学接口代码里一个 try catch，不管内部抛了什么异常，捕获后返回空集合。这让使用方很无奈，很多时候不知道是自己参数传的问题，还是服务方内部的问题，而一旦未知就可能误用了。

```text
public List<Integer> test() {
    try {
        ...
    } catch (Exception e) {
        return Collections.emptyList();
    }
}
```

### 流量控制和限制

生活给了我们答案：比如老式电闸都安装了保险丝，一旦有人使用超大功率的设备，保险丝就会烧断以保护各个电器不被强电流给烧坏。同理我们的接口也需要安装上“保险丝”，以防止非预期的请求对系统压力过大而引起的系统瘫痪，当流量过大时，可以采取拒绝或者引流等机制

## 做好自己

做好自己是个非常大的话题，从需求分析、架构设计 、代码编写、测试、code review、上线、线上服务运维等阶段都可以重点展开介绍，这次简单分享下架构设计、代码编写上的几条经验原则。

### 单一职责原则

略<!--我一直坚持的原则-->

### 控制资源的使用

写代码脑子一定要绷紧一根弦，认知到我们所在的机器资源是有限的。机器资源有哪些？CPU、内存、网络、磁盘等，如果不做好保护控制工作，一旦某一资源满负荷，很容易导致出现线上问题。

**CPU 资源怎么限制**

- 计算算法优化。
- 锁。对于很多服务而言，没有那么多耗费计算资源的算法，但 CPU 使用率也很高，这个时候需要看看锁的使用情况，我的建议是如无必要，尽量不用显式使用锁。
- 习惯问题。比如写循环的时候，千万要检查看看是否能正确退出，有些时候一不小心，在某些条件下就成为死循环
- 尽量使用线程池。通过线程池来限制线程的数目，避免线程过多造成的线程上下文切换的开销。
- JVM 参数调优。

**内存资源怎么限制**

- JVM 参数设置。有一篇朋友写的好文可以参考《Linux 与 JVM 的内存关系分析》。
- 初始化 Java 集合类大小。使用 Java 集合类的时候尽量初始化大小，在长连接服务等耗费内存资源的服务中这种优化非常重要。
- 使用内存池/对象池
- 使用线程池的时候一定要设置队列的最大长度。之前看过好多起故障都是由于队列最大长度没有限制最后导致内存溢出。
- 如果数据较大避免使用本地缓存。如果数据量较大，可以考虑放置到分布式缓存如 Redis、Tair 等，不然 gc 都可能把自己服务卡死。
- 对缓存数据进行压缩。比如之前做推荐相关服务时，需要保存用户偏好数据，如果直接保存可能有 12G，后来采用短文本压缩算法直接压缩到 6G，不过这时一定要考虑好压缩解压缩算法的 cpu 使用率、效率与压缩率的平衡，一些压缩率很高但是性能很差的算法，也不适合线上实时调用。有些时候直接使用 probuf 来序列化之后保存，这样也能节省内存空间。

**网络资源怎么限制**

- 减少调用的次数。经常看到有同学在循环里用 redis/tair 的 get，如果意识到这里面的网络开销的话就应该使用批量处理；又如在推荐服务中经常遇到要去多个地方去取数据，一般采用多线程并行去取数据，这个时候不仅耗费cpu资源，也耗费网络资源，一种在实际中常常采用的方法就是先将很多数据离线存储到一块 ，这时候线上服务只要一个请求就能将所有数据获取。
- 减少传输的数据量。一种方法是压缩后传输，还有一种就是按需传输，比如经常遇到的 getData(int id)，如果我们返回该 id 对应的 Data 所有信息，一来人家不需要，二来数据量传输太大，这个时候可以改为 getData(int id, Listfields)，使用方传输相应的字段过来，服务端只返回使用方需要的字段即可。

**磁盘资源怎么限制**

打日志要控制量，并定期清理。

### 避免单点

不要把鸡蛋放在一个篮子上！从大层次上讲服务可以多机房部署、异地多活；从自己设计角度上讲，服务应该能做到水平扩展。对于很多无状态的服务，通过 nginx、zookeeper 能轻松实现水平扩展；对一些 job 类型的服务，怎么避免单点呢，毕竟只能在一个节点上运行，可以参考《Quartz应用与集群原理分析》一文；对数据服务来说，怎么避免单点呢？简而言之、可以通过分片、分层等方式来实现，后面会有个博文总结。